"""
Facebook Thumbnail Optimizer - PHI√äN B·∫¢N 1080p ULTRA SHARP + AI UPSCALER
- ƒê·ªô ph√¢n gi·∫£i ƒë·∫ßu ra: 1920x1080 (Full HD)
- T·ª± ƒë·ªông d√πng Real-ESRGAN AI upscale n·∫øu ·∫£nh nh·ªè (tr√°nh v·ª° ·∫£nh)
- 4 t·∫ßng l√†m n√©t ch·ªìng l·ªõp + ƒëi·ªÅu ch·ªânh th√¥ng minh
- Kh·ª≠ m√†u cam tri·ªát ƒë·ªÉ + tƒÉng ƒë·ªô trong
"""

from PIL import Image, ImageEnhance, ImageFilter, ImageOps, ImageDraw
import os
import requests
from io import BytesIO
import cv2
import numpy as np
from scipy.signal import convolve2d

# === Th√™m Real-ESRGAN (n·∫øu c√≥) ===
try:
    from realesrgan import RealESRGANer
    from basicsr.archs.rrdbnet_arch import RRDBNet
    HAS_REALESRGAN = True
    print("[AI UPSCALER] Real-ESRGAN s·∫µn s√†ng!")
except ImportError:
    HAS_REALESRGAN = False
    print("[AI UPSCALER] Ch∆∞a c√†i realesrgan ‚Üí s·∫Ω d√πng LANCZOS c·ªï ƒëi·ªÉn (c√≥ th·ªÉ b·ªã v·ª° n·∫øu upscale m·∫°nh)")


class FacebookThumbnailOptimizerUltra:
    OUTPUT_WIDTH = 1920
    OUTPUT_HEIGHT = 1080
    OUTPUT_ASPECT_RATIO = 1920 / 1080
    
    def __init__(self):
        self.output_dir = "thumbnails_optimized"
        os.makedirs(self.output_dir, exist_ok=True)
        print(f"[ULTRA_SHARP_1080p] Output directory: {self.output_dir}")
    
    def optimize_for_facebook(self, image_path, output_filename=None, enhance=True):
        """
        T·ªëi ∆∞u ·∫£nh cho Facebook - PHI√äN B·∫¢N T·ª∞ NHI√äN + AUTO ASPECT RATIO
        - T·ª± ƒë·ªông ph√°t hi·ªán 9:16 (d·ªçc) ho·∫∑c 16:9 (ngang)
        - Ch·ªâ upscale l√™n 720p (ƒë·ªß cho FB, tr√°nh qu√° x·ª≠ l√Ω)
        - Kh√¥ng l√†m n√©t qu√° m·ª©c
        - Gi·ªØ m√†u s·∫Øc t·ª± nhi√™n
        """
        try:
            print(f"\n{'='*60}")
            print("[FB_THUMB] üñºÔ∏è B·∫ÆT ƒê·∫¶U T·ªêI ∆ØU ·∫¢NH")
            print(f"{'='*60}")
            
            # Load image
            if str(image_path).startswith('http'):
                response = requests.get(image_path, timeout=30)
                img = Image.open(BytesIO(response.content))
            else:
                img = Image.open(image_path)
            
            original_size = img.size
            print(f"[FB_THUMB] ·∫¢nh g·ªëc: {original_size}")
            
            # Chu·∫©n h√≥a RGB
            if img.mode in ('RGBA', 'LA', 'P'):
                bg = Image.new('RGB', img.size, (255, 255, 255))
                if img.mode == 'P':
                    img = img.convert('RGBA')
                bg.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
                img = bg
            
            # ============= AUTO-DETECT ASPECT RATIO =============
            aspect_ratio = img.width / img.height
            
            # Ph√°t hi·ªán orientation
            if aspect_ratio < 0.75:  # Portrait (9:16 ho·∫∑c g·∫ßn ƒë√≥)
                TARGET_WIDTH = 720
                TARGET_HEIGHT = 1280
                orientation = "PORTRAIT (9:16)"
                print(f"[FB_THUMB] üì± Ph√°t hi·ªán video d·ªçc ‚Üí Thumbnail {TARGET_WIDTH}x{TARGET_HEIGHT}")
            else:  # Landscape (16:9 ho·∫∑c g·∫ßn ƒë√≥)
                TARGET_WIDTH = 1280
                TARGET_HEIGHT = 720
                orientation = "LANDSCAPE (16:9)"
                print(f"[FB_THUMB] üñ•Ô∏è Ph√°t hi·ªán video ngang ‚Üí Thumbnail {TARGET_WIDTH}x{TARGET_HEIGHT}")
            
            # ============= UPSCALE NH·∫∏ (N·∫æU C·∫¶N) =============
            need_upscale = img.height < TARGET_HEIGHT or img.width < TARGET_WIDTH
            if need_upscale:
                scale_h = TARGET_HEIGHT / img.height
                scale_w = TARGET_WIDTH / img.width
                scale_factor = max(scale_h, scale_w)
                
                print(f"[FB_THUMB] Upscale nh·∫π x{scale_factor:.1f} ‚Üí d√πng LANCZOS ch·∫•t l∆∞·ª£ng cao")
                new_width = int(img.width * scale_factor)
                new_height = int(img.height * scale_factor)
                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                print(f"[FB_THUMB] ‚Üí Sau upscale: {img.size}")
            
            # ============= CROP V·ªÄ TARGET RATIO =============
            img = self._crop_to_ratio(img, TARGET_WIDTH, TARGET_HEIGHT)
            print(f"[FB_THUMB] ‚Üí Sau crop {orientation}: {img.size}")
            
            # ============= RESIZE CH√çNH X√ÅC =============
            if img.size != (TARGET_WIDTH, TARGET_HEIGHT):
                img = img.resize((TARGET_WIDTH, TARGET_HEIGHT), Image.Resampling.LANCZOS)
                print(f"[FB_THUMB] ‚Üí Resize cu·ªëi: {img.size}")
            
            # ============= X·ª¨ L√ù NH·∫∏ (CH·ªà KHI C·∫¶N) =============
            if enhance and need_upscale:
                print("[FB_THUMB] ‚ú® L√†m n√©t nh·∫π (ch·ªâ v√¨ ƒë√£ upscale)...")
                # Ch·ªâ l√†m n√©t r·∫•t nh·∫π ƒë·ªÉ b√π l·∫°i ƒë·ªô m·ªù t·ª´ upscale
                img = self._gentle_sharpen(img)
            else:
                print("[FB_THUMB] ‚úÖ Gi·ªØ nguy√™n ·∫£nh g·ªëc (kh√¥ng c·∫ßn x·ª≠ l√Ω)")
            
            # ============= L∆ØU =============
            if not output_filename:
                from time import strftime
                output_filename = f"fb_natural_{strftime('%Y%m%d_%H%M%S')}.jpg"
            
            output_path = os.path.join(self.output_dir, output_filename)
            # Quality 92 l√† sweet spot (ƒë·ªß n√©t, file nh·ªè)
            img.save(output_path, 'JPEG', quality=92, subsampling=0, optimize=True)
            
            file_size_kb = os.path.getsize(output_path) / 1024
            print(f"\n{'='*60}")
            print(f"[FB_THUMB] ‚úÖ HO√ÄN TH√ÄNH: {output_path}")
            print(f"[FB_THUMB] üìè K√≠ch th∆∞·ªõc: {img.size}")
            print(f"[FB_THUMB] üíæ Dung l∆∞·ª£ng: {file_size_kb:.1f} KB")
            print(f"{'='*60}\n")
            
            return output_path
            
        except Exception as e:
            print(f"[ULTRA] ‚ùå L·ªñI: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    # ================== AI UPSCALE ==================
    def _ai_upscale(self, img, target_scale=4):
        if not HAS_REALESRGAN:
            return img
        
        model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)
        upsampler = RealESRGANer(
            scale=4,
            model_path='https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth',
            model=model,
            tile=400,      # Tile ƒë·ªÉ tr√°nh h·∫øt VRAM/RAM
            tile_pad=10,
            pre_pad=0,
            half=False     # False = CPU, True = GPU (n·∫øu c√≥)
        )
        
        img_np = np.array(img)
        output, _ = upsampler.enhance(img_np, outscale=target_scale)
        return Image.fromarray(output)
    
    
    # ================== CROP ==================
    def _crop_to_ratio(self, img, target_width, target_height):
        """Crop ·∫£nh v·ªÅ t·ª∑ l·ªá mong mu·ªën"""
        target_ratio = target_width / target_height
        img_ratio = img.width / img.height
        
        if img_ratio > target_ratio:
            new_height = img.height
            new_width = int(new_height * target_ratio)
            left = (img.width - new_width) // 2
            img = img.crop((left, 0, left + new_width, new_height))
        else:
            new_width = img.width
            new_height = int(new_width / target_ratio)
            top = (img.height - new_height) // 2
            img = img.crop((0, top, new_width, top + new_height))
        return img
    
    # ================== L√ÄM N√âT NH·∫∏ ==================
    def _gentle_sharpen(self, img):
        """L√†m n√©t r·∫•t nh·∫π nh√†ng - ch·ªâ ƒë·ªÉ b√π l·∫°i ƒë·ªô m·ªù t·ª´ upscale"""
        from PIL import ImageFilter
        # Unsharp mask v·ªõi strength th·∫•p
        return img.filter(ImageFilter.UnsharpMask(radius=1, percent=50, threshold=3))
    
    # ================== X·ª¨ L√ù M√ÄU ==================
    def _remove_color_cast_pro(self, img):
        img_np = np.array(img).astype(np.float32)
        
        # White balance
        avg_b, avg_g, avg_r = np.mean(img_np, axis=(0,1))
        k = (avg_r + avg_g + avg_b) / 3
        img_np[:, :, 0] *= k / (avg_b + 1e-5)
        img_np[:, :, 1] *= k / (avg_g + 1e-5)
        img_np[:, :, 2] *= k / (avg_r + 1e-5)
        
        # Gi·∫£m k√™nh ƒë·ªè th·ª´a
        red_channel = img_np[:, :, 2]
        mask = ((red_channel > 80) & (red_channel < 180)).astype(np.float32) * 0.15
        img_np[:, :, 2] = red_channel * (1 - mask)
        
        # TƒÉng clarity
        img_np = self._apply_clarity(img_np, amount=0.25)
        
        return Image.fromarray(np.clip(img_np, 0, 255).astype(np.uint8))
    
    def _apply_clarity(self, img_np, amount=0.2):
        img_lab = cv2.cvtColor(img_np.astype(np.uint8), cv2.COLOR_RGB2LAB)
        L = img_lab[:, :, 0].astype(np.float32)
        blurred = cv2.GaussianBlur(L, (0, 0), 1.0)
        mask = L - blurred
        L = L + mask * amount
        img_lab[:, :, 0] = np.clip(L, 0, 255).astype(np.uint8)
        return cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB).astype(np.float32)
    
    # ================== SHARPEN PIPELINE ==================
    def _ultra_sharpen_pipeline(self, img, strength_multiplier=1.0):
        img_np = np.array(img).astype(np.float32)
        
        # Blur nh·∫π ch·ªëng artifact t·ª´ upscale
        img_np = cv2.GaussianBlur(img_np, (0, 0), 0.5)
        
        print("[ULTRA]   ‚Üí T·∫ßng 1: Deblur nh·∫π")
        img_np = self._richardson_lucy_deblur(img_np, iterations=5)
        
        print("[ULTRA]   ‚Üí T·∫ßng 2: High-frequency boost")
        img_np = self._high_frequency_boost(img_np, strength=0.35 * strength_multiplier)
        
        print("[ULTRA]   ‚Üí T·∫ßng 3: Edge-aware sharpen")
        img_np = self._edge_aware_sharpen(img_np, radius=1.2, amount=1.8 * strength_multiplier)
        
        print("[ULTRA]   ‚Üí T·∫ßng 4: Micro-texture")
        img_np = self._micro_texture_enhance(img_np, strength=0.4 * strength_multiplier)
        
        # Blend cu·ªëi: 85% n√©t + 15% g·ªëc
        original_np = np.array(img).astype(np.float32)
        img_np = img_np * 0.85 + original_np * 0.15
        
        return Image.fromarray(np.clip(img_np, 0, 255).astype(np.uint8))
    
    # C√°c h√†m sharpen gi·ªØ nguy√™n (ch·ªâ ch·ªânh strength)
    def _richardson_lucy_deblur(self, img_np, iterations=5):
        try:
            def rl_deconvolve(channel, psf, iterations):
                estimate = np.full_like(channel, 0.5)
                for _ in range(iterations):
                    blurred = convolve2d(estimate, psf, 'same')
                    ratio = channel / (blurred + 1e-6)
                    estimate *= convolve2d(ratio, psf[::-1, ::-1], 'same')
                return estimate
            
            psf = np.array([[0.0625, 0.125, 0.0625],
                            [0.125,  0.25,  0.125],
                            [0.0625, 0.125, 0.0625]])
            
            result = np.zeros_like(img_np)
            for i in range(3):
                result[:, :, i] = rl_deconvolve(img_np[:, :, i], psf, iterations)
            return np.clip(result, 0, 255)
        except:
            return img_np
    
    def _high_frequency_boost(self, img_np, strength=0.3):
        blurred = cv2.GaussianBlur(img_np, (0, 0), 1.0)
        high_freq = img_np - blurred
        return img_np + high_freq * strength
    
    def _edge_aware_sharpen(self, img_np, radius=1.0, amount=1.5):
        gray = cv2.cvtColor(img_np.astype(np.uint8), cv2.COLOR_RGB2GRAY)
        edges = cv2.Laplacian(gray, cv2.CV_32F)
        edge_mask = np.abs(edges) > 15
        edge_mask = edge_mask.astype(np.float32)
        edge_mask = cv2.GaussianBlur(edge_mask, (5, 5), 1.0)
        edge_mask = np.clip(edge_mask * 1.5, 0, 1.0)
        
        blurred = cv2.GaussianBlur(img_np, (0, 0), radius)
        sharpened = img_np + (img_np - blurred) * amount
        
        result = img_np * (1 - edge_mask[..., np.newaxis]) + sharpened * edge_mask[..., np.newaxis]
        return result
    
    def _micro_texture_enhance(self, img_np, strength=0.3):
        img_lab = cv2.cvtColor(img_np.astype(np.uint8), cv2.COLOR_RGB2LAB)
        L = img_lab[:, :, 0].astype(np.float32)
        blurred1 = cv2.GaussianBlur(L, (0, 0), 0.8)
        blurred2 = cv2.GaussianBlur(L, (0, 0), 2.0)
        texture = blurred1 - blurred2
        L = L + texture * strength * 2.0
        img_lab[:, :, 0] = np.clip(L, 0, 255).astype(np.uint8)
        return cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB).astype(np.float32)
    
    # ================== TR√çCH FRAME VIDEO ==================
    def create_thumbnail_from_video_frame(self, video_path_or_url, start_percent=0.1, end_percent=0.6, samples=30):
        """Ch·ªçn frame n√©t nh·∫•t t·ª´ video v·ªõi ƒë·ªô ch√≠nh x√°c cao"""
        try:
            print(f"\n[ULTRA] üîç T√¨m frame n√©t nh·∫•t trong video...")
            cap = cv2.VideoCapture(video_path_or_url)
            if not cap.isOpened():
                print("[ULTRA] ‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c video")
                return None
            
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = total_frames / fps if fps > 0 else 0
            
            print(f"[ULTRA]   ‚Üí T·ªïng frames: {total_frames} | FPS: {fps:.2f} | ƒê·ªô d√†i: {duration:.1f}s")
            
            # Qu√©t r·ªông h∆°n ƒë·ªÉ t√¨m frame ƒë·∫πp (10% -> 60% c·ªßa video)
            start_frame = int(total_frames * start_percent) 
            end_frame = int(total_frames * end_percent)
            step = max(1, (end_frame - start_frame) // samples)
            
            best_frame = None
            best_score = 0
            
            for i, frame_idx in enumerate(range(start_frame, end_frame, step)):
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()
                if not ret:
                    continue
                
                # Check resolution on first frame
                if i == 0:
                     h, w = frame.shape[:2]
                     aspect_ratio = w / h
                     
                     # Detect orientation
                     if aspect_ratio < 0.75:
                         orientation = "üì± PORTRAIT (9:16)"
                     else:
                         orientation = "üñ•Ô∏è LANDSCAPE (16:9)"
                     
                     print(f"[ULTRA]   ‚Üí ƒê·ªô ph√¢n gi·∫£i ngu·ªìn: {w}x{h} | {orientation}")
                
                # ƒêa metric scoring: Laplacian variance + Tenengrad
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
                sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
                sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
                tenengrad = np.sum(sobelx**2 + sobely**2) / (gray.shape[0] * gray.shape[1])
                
                # T√≠nh ƒëi·ªÉm ƒë·ªô n√©t
                score = laplacian_var * 0.7 + tenengrad * 0.3
                
                # ∆Øu ti√™n c√°c frame c√≥ ƒë·ªô s√°ng t·ªët (kh√¥ng qu√° t·ªëi/qu√° s√°ng)
                mean_brightness = np.mean(gray)
                if 40 < mean_brightness < 215:
                     score *= 1.2 # Bonus cho frame √°nh s√°ng t·ªët
                else:
                     score *= 0.8 # Ph·∫°t frame qu√° t·ªëi/ch√°y s√°ng
                
                if score > best_score:
                    best_score = score
                    best_frame = frame.copy()
                    best_time = frame_idx / fps if fps > 0 else 0
            
            cap.release()
            
            if best_frame is None:
                print("[ULTRA] ‚ùå Kh√¥ng t√¨m th·∫•y frame ƒë·∫°t chu·∫©n")
                return None
            
            frame_rgb = cv2.cvtColor(best_frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(frame_rgb)
            
            temp_path = os.path.join(self.output_dir, "ultra_frame_best.jpg")
            img.save(temp_path, quality=98)
            
            print(f"[ULTRA] ‚úÖ Ch·ªçn frame t·ªët nh·∫•t t·∫°i {best_time:.2f}s (score: {best_score:.0f})")
            print(f"[ULTRA] üíæ L∆∞u frame t·∫°m: {temp_path}")
            
            return temp_path
            
        except Exception as e:
            print(f"[ULTRA] ‚ùå L·ªói x·ª≠ l√Ω video: {e}")
            return None
    
# ============= DEMO =============
if __name__ == "__main__":
    optimizer = FacebookThumbnailOptimizerUltra()
    
    # Thay ƒë∆∞·ªùng d·∫´n th·∫≠t c·ªßa b·∫°n
    image_path = "anh_goc_cua_ban.jpg"  # ho·∫∑c link http, ho·∫∑c file t·ª´ video
    
    # N·∫øu t·ª´ video:
    # frame_path = optimizer.create_thumbnail_from_video_frame("video.mp4")
    # if frame_path: final = optimizer.optimize_for_facebook(frame_path, "thumb_final.jpg")
    
    final_thumb = optimizer.optimize_for_facebook(image_path, "thumbnail_1080p_ai_net_cang.jpg")
    
    if final_thumb:
        print(f"üéâ Ho√†n th√†nh! File: {final_thumb}")

# ============= ALIAS ƒê·ªÇ T∆Ø∆†NG TH√çCH NG∆Ø·ª¢C =============
# C√°c file kh√°c ƒëang import "FacebookThumbnailOptimizer" (t√™n c≈©)
# Alias n√†y ƒë·∫£m b·∫£o ch√∫ng d√πng ƒë∆∞·ª£c class Ultra m·ªõi
FacebookThumbnailOptimizer = FacebookThumbnailOptimizerUltra